# Python standard library
from os.path import join
from os import listdir
import os, sys

# 3rd party imports from pypi
from snakemake.workflow import workflow as wf_api

# Local imports
from scripts.common import (
    allocated,
    provided,
    references,
    str_bool
)

# Global workflow variables
configfile: 'config.json'                      # Generated from user input and config/*.json
input_vcf  = config['options']['gvcf']
covariates = config['options']['covariates']
phenotype  = config['options']['phenotypes']
workpath   = config['options']['output']
SAMPLES    = []
with open(covariates, 'r') as fh:
    header = next(fh)
    for line in fh:
        sample = line.strip().split('\t')[0]
        SAMPLES.append(sample)

# Final ouput files of the pipeline
# Rule DAG built from listed here
rule all:
    input:
        # Somalier extract
        expand(join(workpath, "somalier_output", "sites", "{sample}.somalier"), sample=SAMPLES),
        # Somalier relate
        join(workpath, "somalier_output", "somalier_relate.samples.tsv"),
        # Somalier ancestry
        join(workpath, "somalier_output", "somalier_ancestry.somalier-ancestry.tsv"),
        # Covariates
        join(workpath,"regenie", "covariates.txt"),

# Import rules
include: join(workpath, "workflow", "rules", "somalier.smk")
#include: join("rules", "vep_slivar.smk")
#include: join("rules", "filtering.smk")
#include: join("rules", "regenie.smk")

# extract sites
